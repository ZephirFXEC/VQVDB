{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9aff71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import struct\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Callable, Sequence, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "# For visualization\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e31cd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from python.VQVAE_v2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6f2801f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 121 .npy files\n",
      "Dataset created with 1154545 total blocks.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VQVAE(\n",
       "  (encoder): EncoderFloat(\n",
       "    (pre): Sequential(\n",
       "      (0): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): GroupNorm(4, 16, eps=1e-05, affine=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): ResidualBlock(\n",
       "        (gn1): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "        (conv1): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (gn2): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      )\n",
       "    )\n",
       "    (down): Conv3d(16, 32, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "    (res_stack): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (gn1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (conv1): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (gn2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      )\n",
       "    )\n",
       "    (attn): ChannelAttention(\n",
       "      (avg_pool): AdaptiveAvgPool3d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=32, out_features=8, bias=False)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Linear(in_features=8, out_features=32, bias=False)\n",
       "        (3): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (proj): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  )\n",
       "  (decoder): DecoderFloat(\n",
       "    (stem): Sequential(\n",
       "      (0): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (res_stack): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (gn1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (gn2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      )\n",
       "    )\n",
       "    (attn): ChannelAttention(\n",
       "      (avg_pool): AdaptiveAvgPool3d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=16, bias=False)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Linear(in_features=16, out_features=64, bias=False)\n",
       "        (3): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (up_conv): Conv3d(64, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (pixshuf): PixelShuffle3D()\n",
       "    (final): Conv3d(32, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  )\n",
       "  (quantizer): VectorQuantizerEMA()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 4096\n",
    "IN_CHANNELS = 1\n",
    "EMBEDDING_DIM = 128  # The dimensionality of the embeddings\n",
    "NUM_EMBEDDINGS = 256  # The size of the codebook (the \"dictionary\")\n",
    "COMMITMENT_COST = 0.25\n",
    "\n",
    "device = \"cuda\"\n",
    "data_dir = \"C:/Users/zphrfx/Desktop/hdk/VQVDB/data/vdb_cache/mix/npy\"\n",
    "\n",
    "\n",
    "model = VQVAE(\n",
    "    in_channels=IN_CHANNELS,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    num_embeddings=NUM_EMBEDDINGS,\n",
    "    commitment_cost=COMMITMENT_COST,\n",
    ").to(device)\n",
    "\n",
    "npy_files = list(Path(data_dir).glob(\"*.npy\"))\n",
    "if not npy_files:\n",
    "    raise ValueError(f\"No .npy files found in /data/npy\")\n",
    "\n",
    "print(f\"Found {len(npy_files)} .npy files\")\n",
    "\n",
    "vdb_dataset = VDBLeafDataset(npy_files=npy_files, include_origins=False, in_channels=IN_CHANNELS)\n",
    "vdb_dataset = torch.utils.data.Subset(vdb_dataset, range(0, len(vdb_dataset), 6))  # Subsample to reduce dataset size\n",
    "# Split dataset randomly with 90% for training and 10% for validation\n",
    "train_size = int(0.8 * len(vdb_dataset))\n",
    "val_size = len(vdb_dataset) - train_size\n",
    "vdb_dataset_train, vdb_dataset_val = torch.utils.data.random_split(\n",
    "    vdb_dataset, [train_size, val_size]\n",
    ")\n",
    "print(f\"Dataset created with {len(vdb_dataset)} total blocks.\")\n",
    "# Save the model state_dict\n",
    "model_path = \"C:/Users/zphrfx/Desktop/hdk/VQVDB/python/models/vqvae.pth\"\n",
    "\n",
    "# Visualize the reconstruction quality for a single example\n",
    "save = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(save[\"state_dict\"])\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cf9db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Visualizing Reconstruction Quality for a Single Example\")\n",
    "\n",
    "# Get a random block from the dataset\n",
    "original_block = vdb_dataset[4543].unsqueeze(0).to(device)\n",
    "\n",
    "# Perform the full compression/decompression cycle\n",
    "indices = model.encode(original_block)\n",
    "reconstructed_block = model.decode(indices)\n",
    "\n",
    "# Detach from GPU and convert to numpy for plotting\n",
    "original_np = original_block.squeeze().cpu().numpy()\n",
    "reconstructed_np = reconstructed_block.squeeze().detach().cpu().numpy()\n",
    "error_np = np.abs(original_np - reconstructed_np)\n",
    "\n",
    "# Get consistent color limits for fair comparison\n",
    "vmin = min(original_np.min(), reconstructed_np.min())\n",
    "vmax = max(original_np.max(), reconstructed_np.max())\n",
    "\n",
    "# --- Plot 1: Slice-by-Slice Comparison ---\n",
    "fig, axes = plt.subplots(3, 3, figsize=(13, 10))\n",
    "center_slice_idx = 4  # Center slice for visualization\n",
    "im1 = axes[0, 0].imshow(original_np[center_slice_idx, :, :], vmin=vmin, vmax=vmax, cmap='viridis')\n",
    "axes[0, 0].set_title(f'Original (Slice Z={center_slice_idx})')\n",
    "axes[0, 0].axis('off')\n",
    "# Reconstructed (Z=4)\n",
    "im2 = axes[0, 1].imshow(reconstructed_np[center_slice_idx, :, :], vmin=vmin, vmax=vmax, cmap='viridis')\n",
    "axes[0, 1].set_title(f'Reconstructed (Slice Z={center_slice_idx})')\n",
    "axes[0, 1].axis('off')\n",
    "# Error Map (Z=4)\n",
    "im3 = axes[0, 2].imshow(error_np[center_slice_idx, :, :], cmap='magma')\n",
    "axes[0, 2].set_title('Absolute Error')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# --- Row 2: Y-Axis Slice ---\n",
    "# Original (Y=4)\n",
    "axes[1, 0].imshow(original_np[:, center_slice_idx, :], vmin=vmin, vmax=vmax, cmap='viridis')\n",
    "axes[1, 0].set_title(f'Original (Slice Y={center_slice_idx})')\n",
    "axes[1, 0].axis('off')\n",
    "# Reconstructed (Y=4)\n",
    "axes[1, 1].imshow(reconstructed_np[:, center_slice_idx, :], vmin=vmin, vmax=vmax, cmap='viridis')\n",
    "axes[1, 1].set_title(f'Reconstructed (Slice Y={center_slice_idx})')\n",
    "axes[1, 1].axis('off')\n",
    "# Error Map (Y=4)\n",
    "axes[1, 2].imshow(error_np[:, center_slice_idx, :], cmap='magma')\n",
    "axes[1, 2].set_title('Absolute Error')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "# --- Row 3: X-Axis Slice ---\n",
    "# Original (X=4)\n",
    "axes[2, 0].imshow(original_np[:, :, center_slice_idx], vmin=vmin, vmax=vmax, cmap='viridis')\n",
    "axes[2, 0].set_title(f'Original (Slice X={center_slice_idx})')\n",
    "axes[2, 0].axis('off')\n",
    "# Reconstructed (X=4)\n",
    "axes[2, 1].imshow(reconstructed_np[:, :, center_slice_idx], vmin=vmin, vmax=vmax, cmap='viridis')\n",
    "axes[2, 1].set_title(f'Reconstructed (Slice X={center_slice_idx})')\n",
    "axes[2, 1].axis('off')\n",
    "# Error Map (X=4)\n",
    "axes[2, 2].imshow(error_np[:, :, center_slice_idx], cmap='magma')\n",
    "axes[2, 2].set_title('Absolute Error')\n",
    "axes[2, 2].axis('off')\n",
    "\n",
    "fig.colorbar(im1, ax=axes[:,:2], orientation='vertical', fraction=.1)\n",
    "fig.colorbar(im3, ax=axes[:,2], orientation='vertical', fraction=.1)\n",
    "plt.suptitle('Qualitative Reconstruction Analysis', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac12362",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(original_np.flatten(), bins=50, alpha=0.7, label='Original')\n",
    "plt.hist(reconstructed_np.flatten(), bins=50, alpha=0.7, label='Reconstructed')\n",
    "plt.title('Histogram of Voxel Values')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "from scipy.stats import entropy\n",
    "def kl_divergence(p, q):\n",
    "    \"\"\"Compute KL divergence between two distributions.\"\"\"\n",
    "    p = p.flatten()\n",
    "    q = q.flatten()\n",
    "    p = p / np.sum(p)  # Normalize\n",
    "    q = q / np.sum(q)  # Normalize\n",
    "    return entropy(p, q)\n",
    "kl_div = kl_divergence(original_np, reconstructed_np)\n",
    "print(f\"KL Divergence between original and reconstructed blocks: {kl_div:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6e3b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot losses and perplexity\n",
    "rl = save['recon_loss_l']\n",
    "vq_loss_l = save['vq_loss_l']\n",
    "perplexity_l = save['perplexity_l']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(np.log(rl), label='Reconstruction Loss', color='blue')\n",
    "plt.plot(np.log(vq_loss_l), label='VQ Loss', color='orange')\n",
    "plt.title('Training Losses')\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(perplexity_l, label='Perplexity', color='green')\n",
    "plt.title('Perplexity Over Training Steps')\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7c7754",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PCA of the learned codebook vectors:\")\n",
    "codebook = model.quantizer.embedding.data.cpu()\n",
    "pca = PCA(n_components=2)\n",
    "codebook_2d = pca.fit_transform(codebook)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(codebook_2d[:, 0], codebook_2d[:, 1], s=15, alpha=0.7)\n",
    "plt.title('VQ-VAE Codebook (PCA Projection)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- Plot 2: Codebook Usage Histogram ---\n",
    "# This is a powerful diagnostic. It requires running the encoder on the whole dataset.\n",
    "print(\"\\nCalculating codebook usage across the entire dataset...\")\n",
    "model.eval()\n",
    "all_indices = []\n",
    "# Create a dataloader without shuffling to iterate through the dataset\n",
    "full_loader = DataLoader(vdb_dataset_val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data_batch in full_loader:\n",
    "        data_batch = data_batch.to(device) # Move data to the same device as the model\n",
    "        indices = model.encode(data_batch)\n",
    "        all_indices.append(indices.cpu().numpy().flatten())\n",
    "\n",
    "all_indices = np.concatenate(all_indices)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(all_indices, bins=NUM_EMBEDDINGS, range=(0, NUM_EMBEDDINGS-1))\n",
    "plt.title('Codebook Usage Frequency')\n",
    "plt.xlabel('Codebook Index')\n",
    "plt.ylabel('Number of Times Used')\n",
    "plt.show()\n",
    "\n",
    "num_dead_codes = NUM_EMBEDDINGS - len(np.unique(all_indices))\n",
    "print(f\"Number of 'dead' (unused) codes: {num_dead_codes} out of {NUM_EMBEDDINGS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb13bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Codebook Perplexity + Active-Code Ratio ---\n",
    "counts = np.bincount(all_indices, minlength=NUM_EMBEDDINGS).astype(np.float64)\n",
    "probs = counts / counts.sum()\n",
    "nonzero = probs > 0\n",
    "perplexity = np.exp(-(probs[nonzero] * np.log(probs[nonzero])).sum())\n",
    "active_ratio = nonzero.mean()\n",
    "\n",
    "print(f\"Codebook perplexity: {perplexity:.2f}\")\n",
    "print(f\"Active-code ratio  : {active_ratio*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ef921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log10\n",
    "\n",
    "def psnr(x, y, vmax=1.0):\n",
    "    mse = torch.mean((x - y) ** 2).item()\n",
    "    return 20 * log10(vmax) - 10 * log10(mse + 1e-12)\n",
    "\n",
    "model.eval()\n",
    "psnr_list, mse_list = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in DataLoader(vdb_dataset, batch_size=BATCH_SIZE, shuffle=False):\n",
    "        batch = batch.to(device)\n",
    "        rec = model.decode(model.encode(batch))\n",
    "        mse = ((batch - rec) ** 2).view(len(batch), -1).mean(dim=1)\n",
    "        mse_list.extend(mse.cpu().numpy())\n",
    "        psnr_list.extend([psnr(b, r) for b, r in zip(batch, rec)])\n",
    "\n",
    "avg_psnr = np.mean(psnr_list)\n",
    "avg_mse = np.mean(mse_list)\n",
    "\n",
    "# Create publication-ready plots\n",
    "plt.style.use('default')\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# PSNR Distribution\n",
    "ax1.hist(psnr_list, bins=40, alpha=0.7, color='steelblue', edgecolor='black', linewidth=0.5)\n",
    "ax1.axvline(avg_psnr, color='crimson', linestyle='--', linewidth=2, \n",
    "           label=f'Mean: {avg_psnr:.1f} dB')\n",
    "ax1.set_xlabel('PSNR (dB)', fontsize=12)\n",
    "ax1.set_ylabel('Number of Blocks', fontsize=12)\n",
    "ax1.set_title('PSNR Distribution', fontsize=13, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.tick_params(labelsize=10)\n",
    "\n",
    "# MSE Distribution\n",
    "ax2.hist(mse_list, bins=40, alpha=0.7, color='forestgreen', edgecolor='black', linewidth=0.5)\n",
    "ax2.axvline(avg_mse, color='crimson', linestyle='--', linewidth=2,\n",
    "           label=f'Mean: {avg_mse:.2e}')\n",
    "ax2.set_xlabel('MSE', fontsize=12)\n",
    "ax2.set_ylabel('Number of Blocks (log scale)', fontsize=12)\n",
    "ax2.set_title('MSE Distribution', fontsize=13, fontweight='bold')\n",
    "ax2.set_yscale('log')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.tick_params(labelsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Reconstruction Quality Metrics:\")\n",
    "print(f\"Average PSNR: {avg_psnr:.2f} dB\")\n",
    "print(f\"Average MSE: {avg_mse:.2e}\")\n",
    "print(f\"PSNR std: {np.std(psnr_list):.2f} dB\")\n",
    "print(f\"MSE std: {np.std(mse_list):.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f19461",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 100000\n",
    "orig_sample = original_np.flatten()\n",
    "recon_sample = reconstructed_np.flatten()\n",
    "if len(orig_sample) > n_points:\n",
    "    idx = np.random.choice(len(orig_sample), n_points, replace=False)\n",
    "    orig_sample = orig_sample[idx]; recon_sample = recon_sample[idx]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(orig_sample, recon_sample, s=2, alpha=.5)\n",
    "lims = [min(orig_sample.min(), recon_sample.min()),\n",
    "        max(orig_sample.max(), recon_sample.max())]\n",
    "plt.plot(lims, lims, 'k--', linewidth=1)\n",
    "plt.xlabel('Original voxel'); plt.ylabel('Reconstructed voxel')\n",
    "plt.title('Voxel-wise Scatter (diag = perfect)')\n",
    "plt.grid(True, alpha=.3); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20837d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- L2 norm of each embedding vector ---\n",
    "embed_norm = torch.linalg.norm(model.quantizer.embedding.data, dim=1).cpu().numpy()\n",
    "plt.figure(figsize=(10,2))\n",
    "plt.bar(range(NUM_EMBEDDINGS), embed_norm, width=1.0)\n",
    "plt.title('Codebook Embedding L2 Norms'); plt.xlabel('Code Index'); plt.ylabel('Norm')\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f22a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mip(vol, axis):\n",
    "    \"\"\"Maximum-intensity projection along a single axis.\"\"\"\n",
    "    return vol.max(axis=axis)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 7))\n",
    "views = [(0, 'XY MIP'),   # collapse Z\n",
    "         (1, 'XZ MIP'),   # collapse Y\n",
    "         (2, 'YZ MIP')]   # collapse X\n",
    "\n",
    "for col, (axis_to_collapse, title) in enumerate(views):\n",
    "    axes[0, col].imshow(mip(original_np, axis=axis_to_collapse), cmap='viridis')\n",
    "    axes[0, col].set_title(f'Original {title}')\n",
    "    axes[0, col].axis('off')\n",
    "\n",
    "    axes[1, col].imshow(mip(reconstructed_np, axis=axis_to_collapse), cmap='viridis')\n",
    "    axes[1, col].set_title(f'Reconstructed {title}')\n",
    "    axes[1, col].axis('off')\n",
    "\n",
    "plt.suptitle('Maximum-Intensity Projections (3-view)', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c617293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 1. Build a per-block latent vector ----------\n",
    "model.eval()\n",
    "latents, errs = [], []          # errs = optional colouring\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in DataLoader(vdb_dataset_val,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=False):\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        idx = model.encode(batch).long()               # (B, Z, Y, X) indices\n",
    "        emb = model.quantizer.embedding[idx.view(-1)]  # (B*Z*Y*X, C)\n",
    "        emb = emb.view(*idx.shape, -1)                 # (B, Z, Y, X, C)\n",
    "        mean_emb = emb.mean(dim=(1, 2, 3))             # (B, C)\n",
    "        latents.append(mean_emb.cpu())\n",
    "        \n",
    "        # Optional: per-block MSE for coloured scatter\n",
    "        rec = model.decode(idx)\n",
    "        errs.append(((batch - rec) ** 2)\n",
    "                    .view(len(batch), -1)\n",
    "                    .mean(dim=1)\n",
    "                    .cpu())\n",
    "\n",
    "latents = torch.cat(latents, dim=0).numpy()   # (N, C)\n",
    "errs    = torch.cat(errs, dim=0).numpy()      # (N,)\n",
    "\n",
    "# ---------- 2. PCA to 2-D ----------\n",
    "from sklearn.decomposition import FastICA\n",
    "pca2 = FastICA(n_components=2, random_state=0)\n",
    "latents_2d = pca2.fit_transform(latents)      # (N, 2)\n",
    "\n",
    "# ---------- 3. Scatter with viridis ----------\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "sc = plt.scatter(latents_2d[:, 0],\n",
    "                 latents_2d[:, 1],\n",
    "                 c=errs,                 # <- set to None for uniform colour\n",
    "                 cmap='viridis',\n",
    "                 s=4,\n",
    "                 alpha=0.8)\n",
    "if sc.get_array() is not None:           # only if colouring by a value\n",
    "    plt.colorbar(sc, label='Block MSE')\n",
    "\n",
    "plt.title('Latent Space Sampling (PCA-2D, viridis)')\n",
    "plt.xlabel('PC-1'); plt.ylabel('PC-2')\n",
    "plt.grid(True, alpha=.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34969123",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_original_np = []\n",
    "all_reconstructed_np = []\n",
    "\n",
    "import tqdm\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "print(f\"Processing {BATCH_SIZE} batches for analysis...\")\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(tqdm.tqdm(DataLoader(vdb_dataset_val, batch_size=BATCH_SIZE, shuffle=False))):\n",
    "        if i >= BATCH_SIZE:\n",
    "            break\n",
    "        \n",
    "        original_block = batch.to(device)\n",
    "        indices = model.encode(original_block)\n",
    "        reconstructed_block = model.decode(indices)\n",
    "        \n",
    "        # Permute to (B, D, H, W, C) for easier component-wise processing\n",
    "        all_original_np.append(original_block.permute(0, 2, 3, 4, 1).cpu().numpy())\n",
    "        all_reconstructed_np.append(reconstructed_block.permute(0, 2, 3, 4, 1).cpu().numpy())\n",
    "\n",
    "# Concatenate all batches into large numpy arrays\n",
    "original_np = np.concatenate(all_original_np)\n",
    "reconstructed_np = np.concatenate(all_reconstructed_np)\n",
    "\n",
    "print(f\"Analysis will be performed on {original_np.size} individual float values.\")\n",
    "\n",
    "# --- 4. Define the Log-Binning Function and Calculate Quantities ---\n",
    "\n",
    "def log_bin_value(v_np):\n",
    "    \"\"\"\n",
    "    Computes int(clamp(log2(abs(v)) + 24, 0, 31)) for a numpy array.\n",
    "    A small epsilon is added to handle log2(0).\n",
    "    \"\"\"\n",
    "    # Epsilon to avoid log2(0) -> -inf\n",
    "    epsilon = 1e-30\n",
    "    log2_val = np.log2(np.abs(v_np) + epsilon)\n",
    "    binned = np.clip(log2_val + 24, 0, 31)\n",
    "    return binned.astype(np.int32)\n",
    "\n",
    "print(\"Calculating binned quantities...\")\n",
    "# Calculate the four primary quantities\n",
    "v_in_binned = log_bin_value(original_np)\n",
    "v_out_binned = log_bin_value(reconstructed_np)\n",
    "\n",
    "# Calculate errors before binning\n",
    "abs_error_np = np.abs(original_np - reconstructed_np)\n",
    "# Add epsilon to denominator to avoid division by zero\n",
    "rel_error_np = abs_error_np / (np.abs(original_np) + 1e-9)\n",
    "\n",
    "abs_err_binned = log_bin_value(abs_error_np)\n",
    "rel_err_binned = log_bin_value(rel_error_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4171ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 5. Create the 2D Histograms ---\n",
    "print(\"Generating 2D histograms...\")\n",
    "\n",
    "# Define the 6 plots we want to create\n",
    "plots_to_make = [\n",
    "    {'x': v_in_binned, 'y': v_out_binned, 'title': 'Input vs. Output', 'xlabel': 'Log-Binned Input', 'ylabel': 'Log-Binned Output'},\n",
    "    {'x': v_in_binned, 'y': abs_err_binned, 'title': 'Input vs. Absolute Error', 'xlabel': 'Log-Binned Input', 'ylabel': 'Log-Binned Abs Error'},\n",
    "    {'x': v_in_binned, 'y': rel_err_binned, 'title': 'Input vs. Relative Error', 'xlabel': 'Log-Binned Input', 'ylabel': 'Log-Binned Rel Error'},\n",
    "    {'x': v_out_binned, 'y': abs_err_binned, 'title': 'Output vs. Absolute Error', 'xlabel': 'Log-Binned Output', 'ylabel': 'Log-Binned Abs Error'},\n",
    "    {'x': v_out_binned, 'y': rel_err_binned, 'title': 'Output vs. Relative Error', 'xlabel': 'Log-Binned Output', 'ylabel': 'Log-Binned Rel Error'},\n",
    "    {'x': abs_err_binned, 'y': rel_err_binned, 'title': 'Absolute vs. Relative Error', 'xlabel': 'Log-Binned Abs Error', 'ylabel': 'Log-Binned Rel Error'}\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 11), constrained_layout=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Bins for a 32x32 histogram (from 0 to 31)\n",
    "bins = np.arange(33) - 0.5\n",
    "\n",
    "for i, plot_info in enumerate(plots_to_make):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Flatten the arrays to create the 1D list of values for the histogram\n",
    "    x_data = plot_info['x'].flatten()\n",
    "    y_data = plot_info['y'].flatten()\n",
    "    \n",
    "    # Create the 2D histogram\n",
    "    hist, xedges, yedges = np.histogram2d(x_data, y_data, bins=bins)\n",
    "    \n",
    "    # Use LogNorm for the color scale to see low-count bins. vmin=1 avoids log(0)\n",
    "    # Transpose hist (H.T) because imshow's axes are swapped compared to histogram2d's\n",
    "    im = ax.imshow(hist.T, origin='lower', cmap='magma', norm=LogNorm(vmin=1))\n",
    "    \n",
    "    ax.set_title(plot_info['title'], fontsize=14)\n",
    "    ax.set_xlabel(plot_info['xlabel'], fontsize=10)\n",
    "    ax.set_ylabel(plot_info['ylabel'], fontsize=10)\n",
    "    \n",
    "    # Set ticks to be the bin centers\n",
    "    tick_locs = np.arange(0, 32, 4)\n",
    "    ax.set_xticks(tick_locs)\n",
    "    ax.set_yticks(tick_locs)\n",
    "    \n",
    "    fig.colorbar(im, ax=ax, label=\"Counts (log scale)\")\n",
    "\n",
    "fig.suptitle(\"Log-Binned Error Analysis of VQ-VAE Reconstruction\", fontsize=22)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
