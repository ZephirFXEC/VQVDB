{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aff71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, math, struct, argparse\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from scipy.stats import entropy\n",
    "import tqdm\n",
    "\n",
    "from python.VQVAE_v2 import *\n",
    "\n",
    "device = \"cuda\"\n",
    "BATCH_SIZE = 2048\n",
    "NUM_EMBEDDINGS = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f2801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir   = r\"C:/Users/zphrfx/Desktop/hdk/VQVDB/data/vdb_cache/mix/npy\"\n",
    "model_path = r\"C:/Users/zphrfx/Desktop/hdk/VQVDB/models/scalar/vqvae_scripted_128_256_singlechannel_residual.pt\"\n",
    "\n",
    "model = torch.jit.load(model_path, map_location=device).eval()\n",
    "\n",
    "npy_files = list(Path(data_dir).glob(\"*.npy\"))\n",
    "dataset   = VDBLeafDataset(npy_files, include_origins=False, in_channels=1)\n",
    "dataset   = torch.utils.data.Subset(dataset, range(0, len(dataset), 4))\n",
    "\n",
    "train_sz = int(0.2 * len(dataset))\n",
    "val_sz   = len(dataset) - train_sz\n",
    "_, val_ds = torch.utils.data.random_split(dataset, [train_sz, val_sz])\n",
    "\n",
    "print(f\"Validation blocks: {len(val_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cf9db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def run_once(dataloader):\n",
    "    \"\"\"Returns dict with everything we need later.\"\"\"\n",
    "    out = {\n",
    "        \"orig\" : [],          # original blocks (np.float32)\n",
    "        \"rec\"  : [],          # reconstructed blocks\n",
    "        \"idx\"  : [],          # codebook indices (int32)\n",
    "        \"mse\"  : [],          # per-block MSE\n",
    "        \"psnr\" : [],          # per-block PSNR\n",
    "        \"lat\"  : [],          # per-block mean latent vector\n",
    "    }\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Forward pass\"):\n",
    "        x = batch.to(device)\n",
    "        idx = model.encode(x)                       # (B, Z, Y, X)\n",
    "        rec = model.decode(idx)\n",
    "\n",
    "        # --- metrics ---\n",
    "        mse = ((x - rec) ** 2).view(x.size(0), -1).mean(1)\n",
    "        psnr = 20 * math.log10(1.0) - 10 * torch.log10(mse + 1e-12)\n",
    "\n",
    "        # --- latent vector (mean over spatial dims) ---\n",
    "        emb = model.quantizer.embedding[idx.view(-1)].view(*idx.shape, -1)  # (B,Z,Y,X,C)\n",
    "        mean_lat = emb.mean(dim=(1, 2, 3))                                  # (B,C)\n",
    "\n",
    "        out[\"orig\"].append(x.cpu().numpy())\n",
    "        out[\"rec\"].append(rec.cpu().numpy())\n",
    "        out[\"idx\"].append(idx.cpu().numpy())\n",
    "        out[\"mse\"].append(mse.cpu().numpy())\n",
    "        out[\"psnr\"].append(psnr.cpu().numpy())\n",
    "        out[\"lat\"].append(mean_lat.cpu().numpy())\n",
    "\n",
    "    # concatenate lists → numpy arrays\n",
    "    for k in out:\n",
    "        out[k] = np.concatenate(out[k])\n",
    "    return out\n",
    "\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)\n",
    "cache = run_once(val_loader)\n",
    "print(\"Single-pass complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac12362",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 432 % len(val_ds)   # pick a deterministic block\n",
    "orig = cache[\"orig\"][i].squeeze()\n",
    "rec  = cache[\"rec\"][i].squeeze()\n",
    "err  = np.abs(orig - rec)\n",
    "\n",
    "vmin, vmax = orig.min(), orig.max()\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "ax[0].imshow(orig[4], vmin=vmin, vmax=vmax, cmap='viridis'); ax[0].set_title(\"Original\")\n",
    "ax[1].imshow(rec[4],  vmin=vmin, vmax=vmax, cmap='viridis'); ax[1].set_title(\"Reconstructed\")\n",
    "ax[2].imshow(err[4], cmap='magma');                          ax[2].set_title(\"Error\")\n",
    "for a in ax: a.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6e3b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mse  = cache[\"mse\"].mean()\n",
    "avg_psnr = cache[\"psnr\"].mean()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax[0].hist(cache[\"psnr\"], bins=100, color='steelblue', edgecolor='k')\n",
    "ax[0].axvline(avg_psnr, color='r', ls='--', label=f\"Mean {avg_psnr:.1f} dB\")\n",
    "ax[0].set_title(\"PSNR Distribution\"); ax[0].legend()\n",
    "\n",
    "ax[1].hist(cache[\"mse\"], bins=100, color='forestgreen', edgecolor='k')\n",
    "ax[1].axvline(avg_mse, color='r', ls='--', label=f\"Mean {avg_mse:.2e}\")\n",
    "ax[1].set_yscale('log')\n",
    "ax[1].set_title(\"MSE Distribution\"); ax[1].legend()\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7c7754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- codebook PCA ---\n",
    "codebook = model.quantizer.embedding.data.cpu()\n",
    "pca_cb = PCA(n_components=2).fit_transform(codebook)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(pca_cb[:, 0], pca_cb[:, 1], s=15, alpha=.7)\n",
    "plt.title(\"Codebook PCA\"); plt.grid(True); plt.show()\n",
    "\n",
    "# --- latent space PCA (coloured by MSE) ---\n",
    "latents = cache[\"lat\"]\n",
    "lat_2d  = FastICA(n_components=2, random_state=0).fit_transform(latents)\n",
    "plt.figure(figsize=(7, 7))\n",
    "sc = plt.scatter(lat_2d[:, 0], lat_2d[:, 1], c=cache[\"mse\"], s=4,\n",
    "                 cmap='viridis', alpha=.8, norm=LogNorm())\n",
    "plt.colorbar(sc, label='Block MSE')\n",
    "plt.title(\"Latent Space (ICA-2D)\"); plt.grid(True); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb13bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_bin(v):\n",
    "    return np.clip(np.log2(np.abs(v) + 1e-30) + 24, 0, 31).astype(np.int32)\n",
    "\n",
    "orig_flat = cache[\"orig\"].flatten()\n",
    "rec_flat  = cache[\"rec\"].flatten()\n",
    "abs_err   = np.abs(orig_flat - rec_flat)\n",
    "rel_err   = abs_err / (np.abs(orig_flat) + 1e-9)\n",
    "\n",
    "bins = np.arange(33) - .5\n",
    "pairs = [\n",
    "    (log_bin(orig_flat), log_bin(rec_flat),  \"Input vs Output\"),\n",
    "    (log_bin(orig_flat), log_bin(abs_err),   \"Input vs AbsErr\"),\n",
    "    (log_bin(orig_flat), log_bin(rel_err),   \"Input vs RelErr\"),\n",
    "    (log_bin(rec_flat),  log_bin(abs_err),   \"Output vs AbsErr\"),\n",
    "    (log_bin(rec_flat),  log_bin(rel_err),   \"Output vs RelErr\"),\n",
    "    (log_bin(abs_err),   log_bin(rel_err),   \"AbsErr vs RelErr\"),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 11))\n",
    "axes = axes.flatten()\n",
    "for ax, (x, y, title) in zip(axes, pairs):\n",
    "    h, *_ = np.histogram2d(x, y, bins=bins)\n",
    "    ax.imshow(h.T, origin='lower', cmap='magma', norm=LogNorm(vmin=1))\n",
    "    ax.set_title(title); ax.set_xlabel(\"log2 bin\"); ax.set_ylabel(\"log2 bin\")\n",
    "    ax.set_xticks(np.arange(0, 32, 4)); ax.set_yticks(np.arange(0, 32, 4))\n",
    "plt.suptitle(\"Log-Binned Error Analysis\"); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7a89d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = cache[\"orig\"].flatten()\n",
    "rec  = cache[\"rec\"].flatten()\n",
    "signed_err = rec - orig\n",
    "\n",
    "mag_bin = np.clip(np.log2(np.abs(orig) + 1e-30) + 24, 0, 31).astype(int)\n",
    "df = np.column_stack((mag_bin, signed_err))\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hexbin(orig, signed_err, gridsize=150, cmap='coolwarm', norm=LogNorm())\n",
    "plt.colorbar(label='Counts')\n",
    "plt.axhline(0, color='k', lw=.5)\n",
    "plt.xlabel('Original voxel value')\n",
    "plt.ylabel('Signed error (Recon – Orig)')\n",
    "plt.title('Signed Error vs Input Magnitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf33aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_edges = np.quantile(orig, np.linspace(0, 1, 50))   # 10 quantiles\n",
    "mse_q = []\n",
    "for lo, hi in zip(q_edges[:-1], q_edges[1:]):\n",
    "    mask = (orig >= lo) & (orig < hi)\n",
    "    mse_q.append(((rec[mask] - orig[mask])**2).mean())\n",
    "\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.plot(q_edges[1:], mse_q, marker='o')\n",
    "plt.xscale('symlog')\n",
    "plt.xlabel('Input quantile upper edge')\n",
    "plt.ylabel('MSE within quantile')\n",
    "plt.title('MSE across Input Magnitude Quantiles')\n",
    "plt.grid(True, alpha=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ba568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_zero = orig == 0\n",
    "zero_mse  = ((rec - orig)[mask_zero]**2).mean()\n",
    "nonzero_mse = ((rec - orig)[~mask_zero]**2).mean()\n",
    "\n",
    "print(f\"MSE on zero-valued voxels:   {zero_mse:.2e}\")\n",
    "print(f\"MSE on non-zero voxels:      {nonzero_mse:.2e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
