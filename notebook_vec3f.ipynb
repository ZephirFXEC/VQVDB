{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aff71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Callable, Sequence, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "# For visualization\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae509fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from python.VQVAE_v2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2360bdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8192\n",
    "EPOCHS = 50\n",
    "LR = 5e-4\n",
    "IN_CHANNELS = 3\n",
    "EMBEDDING_DIM = 128  # The dimensionality of the embeddings\n",
    "NUM_EMBEDDINGS = 1024  # The size of the codebook (the \"dictionary\")\n",
    "COMMITMENT_COST = 0.25\n",
    "\n",
    "device = \"cuda\"\n",
    "data_dir = \"C:/Users/zphrfx/Desktop/hdk/VQVDB/data/vdb_cache/npy\"\n",
    "\n",
    "\n",
    "model = VQVAE(\n",
    "    in_channels=IN_CHANNELS,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    num_embeddings=NUM_EMBEDDINGS,\n",
    "    commitment_cost=COMMITMENT_COST,\n",
    ").to(device)\n",
    "\n",
    "npy_files = list(Path(data_dir).glob(\"*.npy\"))\n",
    "if not npy_files:\n",
    "    raise ValueError(f\"No .npy files found in /data/npy\")\n",
    "\n",
    "print(f\"Found {len(npy_files)} .npy files\")\n",
    "\n",
    "vdb_dataset = VDBLeafDataset(npy_files=npy_files, include_origins=False, in_channels=IN_CHANNELS)\n",
    "\n",
    "# Save the model state_dict\n",
    "model_path = \"C:/Users/zphrfx/Desktop/hdk/VQVDB/python/models/vqvae.pth\"\n",
    "\n",
    "# Visualize the reconstruction quality for a single example\n",
    "save = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(save[\"state_dict\"])\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cf9db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Load and Reconstruct Data (same as before) ---\n",
    "print(\"Visualizing Reconstruction Quality for the full 8x8x8 block\")\n",
    "\n",
    "# Use a good example from your dataset\n",
    "original_block = vdb_dataset[5466].unsqueeze(0).to(device)  \n",
    "\n",
    "print(\"Performing reconstruction...\")\n",
    "model.eval() # Ensure model is in eval mode\n",
    "with torch.no_grad():\n",
    "    indices = model.encode(original_block)\n",
    "    reconstructed_block = model.decode(indices)\n",
    "    \n",
    "orig = original_block     # (1,C,8,8,8)\n",
    "recon = reconstructed_block\n",
    "\n",
    "\n",
    "# --- 2. Prepare Data for Plotting ---\n",
    "# Convert to NumPy and permute from (C, D, H, W) to (D, H, W, C) for plotting\n",
    "original_np = orig.squeeze(0).permute(1, 2, 3, 0).cpu().numpy()\n",
    "reconstructed_np = reconstructed_block.squeeze(0).permute(1, 2, 3, 0).cpu().numpy()\n",
    "\n",
    "# --- 3. Helper function for the 2D RGB Montage ---\n",
    "def create_rgb_montage(volume_data, grid_layout=(2, 4)):\n",
    "    \"\"\"\n",
    "    Creates a 2D image montage from a 3D vector volume by mapping XYZ to RGB.\n",
    "    \"\"\"\n",
    "    # Normalize vector components from [-1, 1] to color components [0, 1]\n",
    "    rgb_volume = (volume_data * 0.5) + 0.5\n",
    "    \n",
    "    depth, height, width, _ = rgb_volume.shape\n",
    "    rows, cols = grid_layout\n",
    "    \n",
    "    # Ensure the grid layout matches the number of slices\n",
    "    if rows * cols != depth:\n",
    "        raise ValueError(\"Grid layout does not match the number of slices in the volume.\")\n",
    "        \n",
    "    montage = np.zeros((rows * height, cols * width, 3))\n",
    "    \n",
    "    for i in range(depth):\n",
    "        row_idx = i // cols\n",
    "        col_idx = i % cols\n",
    "        \n",
    "        slice_img = rgb_volume[i, :, :, :]\n",
    "        \n",
    "        # Place the slice into the correct position in the montage\n",
    "        montage[row_idx * height:(row_idx + 1) * height,\n",
    "                col_idx * width:(col_idx + 1) * width, :] = slice_img\n",
    "                \n",
    "    return montage\n",
    "\n",
    "# --- 4. Plotting ---\n",
    "print(\"Generating plots...\")\n",
    "fig = plt.figure(figsize=(16, 14))\n",
    "fig.suptitle('Full 8x8x8 Block Reconstruction', fontsize=24)\n",
    "\n",
    "# --- Top Row: 3D Quiver Plots ---\n",
    "\n",
    "# Create the 3D coordinate grid for the arrows\n",
    "grid_size = original_np.shape[0]\n",
    "X, Y, Z = np.meshgrid(np.arange(grid_size), np.arange(grid_size), np.arange(grid_size))\n",
    "\n",
    "# Extract vector components (U, V, W)\n",
    "U_orig, V_orig, W_orig = original_np[:,:,:,0], original_np[:,:,:,1], original_np[:,:,:,2]\n",
    "U_recon, V_recon, W_recon = reconstructed_np[:,:,:,0], reconstructed_np[:,:,:,1], reconstructed_np[:,:,:,2]\n",
    "\n",
    "# Plot 1: Original 3D Quiver\n",
    "ax1 = fig.add_subplot(2, 2, 1, projection='3d')\n",
    "ax1.set_title('Original 3D Vector Field', fontsize=16)\n",
    "ax1.quiver(X, Y, Z, U_orig, V_orig, W_orig, length=0.6, normalize=False, alpha=0.8)\n",
    "ax1.set_xlabel('X'); ax1.set_ylabel('Y'); ax1.set_zlabel('Z')\n",
    "ax1.view_init(elev=25., azim=-45) # Set a good camera angle\n",
    "\n",
    "# Plot 2: Reconstructed 3D Quiver\n",
    "ax2 = fig.add_subplot(2, 2, 2, projection='3d')\n",
    "ax2.set_title('Reconstructed 3D Vector Field', fontsize=16)\n",
    "ax2.quiver(X, Y, Z, U_recon, V_recon, W_recon, length=0.6, normalize=False, alpha=0.8)\n",
    "ax2.set_xlabel('X'); ax2.set_ylabel('Y'); ax2.set_zlabel('Z')\n",
    "ax2.view_init(elev=25., azim=-45) # Use the same camera angle\n",
    "\n",
    "# --- Bottom Row: 2D RGB Montages ---\n",
    "\n",
    "# Plot 3: Original 2D Montage\n",
    "ax3 = fig.add_subplot(2, 2, 3)\n",
    "ax3.set_title('Original as 2D RGB Montage', fontsize=16)\n",
    "original_montage = create_rgb_montage(original_np)\n",
    "ax3.imshow(original_montage)\n",
    "ax3.axis('off')\n",
    "\n",
    "# Plot 4: Reconstructed 2D Montage\n",
    "ax4 = fig.add_subplot(2, 2, 4)\n",
    "ax4.set_title('Reconstructed as 2D RGB Montage', fontsize=16)\n",
    "reconstructed_montage = create_rgb_montage(reconstructed_np)\n",
    "ax4.imshow(reconstructed_montage)\n",
    "ax4.axis('off')\n",
    "\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust for suptitle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6e3b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot losses and perplexity\n",
    "rl = np.log(save['recon_loss_l'])\n",
    "vq_loss_l = np.log(save['vq_loss_l'])\n",
    "perplexity_l = save['perplexity_l']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(rl, label='Reconstruction Loss', color='blue')\n",
    "plt.plot(vq_loss_l, label='VQ Loss', color='orange')\n",
    "plt.title('Training Losses')\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(perplexity_l, label='Perplexity', color='green')\n",
    "plt.title('Perplexity Over Training Steps')\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac12362",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(original_np.flatten(), bins=50, alpha=0.7, label='Original')\n",
    "plt.hist(reconstructed_np.flatten(), bins=50, alpha=0.7, label='Reconstructed')\n",
    "plt.title('Histogram of Voxel Values')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "from scipy.stats import entropy\n",
    "def kl_divergence(p, q):\n",
    "    \"\"\"Compute KL divergence between two distributions.\"\"\"\n",
    "    p = p.flatten()\n",
    "    q = q.flatten()\n",
    "    p = p / np.sum(p)  # Normalize\n",
    "    q = q / np.sum(q)  # Normalize\n",
    "    return entropy(p, q)\n",
    "kl_div = kl_divergence(original_np , reconstructed_np)\n",
    "print(f\"KL Divergence between original and reconstructed blocks: {kl_div:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7c7754",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PCA of the learned codebook vectors:\")\n",
    "codebook = model.quantizer.embedding.data.cpu()\n",
    "pca = PCA(n_components=2)\n",
    "codebook_2d = pca.fit_transform(codebook)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(codebook_2d[:, 0], codebook_2d[:, 1], s=15, alpha=0.7)\n",
    "plt.title('VQ-VAE Codebook (PCA Projection)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- Plot 2: Codebook Usage Histogram ---\n",
    "# This is a powerful diagnostic. It requires running the encoder on the whole dataset.\n",
    "print(\"\\nCalculating codebook usage across the entire dataset...\")\n",
    "model.eval()\n",
    "all_indices = []\n",
    "full_loader = DataLoader(vdb_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data_batch in full_loader:\n",
    "        data_batch = data_batch.to(device) # Move data to the same device as the model\n",
    "        indices = model.encode(data_batch)\n",
    "        all_indices.append(indices.cpu().numpy().flatten())\n",
    "\n",
    "all_indices = np.concatenate(all_indices)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(all_indices, bins=NUM_EMBEDDINGS, range=(0, NUM_EMBEDDINGS-1))\n",
    "plt.title('Codebook Usage Frequency')\n",
    "plt.xlabel('Codebook Index')\n",
    "plt.ylabel('Number of Times Used')\n",
    "plt.show()\n",
    "\n",
    "num_dead_codes = NUM_EMBEDDINGS - len(np.unique(all_indices))\n",
    "print(f\"Number of 'dead' (unused) codes: {num_dead_codes} out of {NUM_EMBEDDINGS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb13bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Codebook Perplexity + Active-Code Ratio ---\n",
    "counts = np.bincount(all_indices, minlength=NUM_EMBEDDINGS).astype(np.float64)\n",
    "probs = counts / counts.sum()\n",
    "nonzero = probs > 0\n",
    "perplexity = np.exp(-(probs[nonzero] * np.log(probs[nonzero])).sum())\n",
    "active_ratio = nonzero.mean()\n",
    "\n",
    "print(f\"Codebook perplexity: {perplexity:.2f}\")\n",
    "print(f\"Active-code ratio  : {active_ratio*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ef921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log10\n",
    "\n",
    "def psnr(x, y, vmax=1.0):\n",
    "    mse = torch.mean((x - y) ** 2).item()\n",
    "    return 20 * log10(vmax) - 10 * log10(mse + 1e-12)\n",
    "\n",
    "model.eval()\n",
    "psnr_list, mse_list = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in DataLoader(vdb_dataset, batch_size=BATCH_SIZE, shuffle=False):\n",
    "        batch = batch.to(device)\n",
    "        rec = model.decode(model.encode(batch))\n",
    "        mse = ((batch - rec) ** 2).view(len(batch), -1).mean(dim=1)\n",
    "        mse_list.extend(mse.cpu().numpy())\n",
    "        psnr_list.extend([psnr(b, r) for b, r in zip(batch, rec)])\n",
    "\n",
    "avg_psnr = np.mean(psnr_list)\n",
    "avg_mse = np.mean(mse_list)\n",
    "\n",
    "# Create publication-ready plots\n",
    "plt.style.use('default')\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# PSNR Distribution\n",
    "ax1.hist(psnr_list, bins=40, alpha=0.7, color='steelblue', edgecolor='black', linewidth=0.5)\n",
    "ax1.axvline(avg_psnr, color='crimson', linestyle='--', linewidth=2, \n",
    "           label=f'Mean: {avg_psnr:.1f} dB')\n",
    "ax1.set_xlabel('PSNR (dB)', fontsize=12)\n",
    "ax1.set_ylabel('Number of Blocks', fontsize=12)\n",
    "ax1.set_title('PSNR Distribution', fontsize=13, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.tick_params(labelsize=10)\n",
    "\n",
    "# MSE Distribution\n",
    "ax2.hist(mse_list, bins=40, alpha=0.7, color='forestgreen', edgecolor='black', linewidth=0.5)\n",
    "ax2.axvline(avg_mse, color='crimson', linestyle='--', linewidth=2,\n",
    "           label=f'Mean: {avg_mse:.2e}')\n",
    "ax2.set_xlabel('MSE', fontsize=12)\n",
    "ax2.set_ylabel('Number of Blocks (log scale)', fontsize=12)\n",
    "ax2.set_title('MSE Distribution', fontsize=13, fontweight='bold')\n",
    "ax2.set_yscale('log')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.tick_params(labelsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Reconstruction Quality Metrics:\")\n",
    "print(f\"Average PSNR: {avg_psnr:.2f} dB\")\n",
    "print(f\"Average MSE: {avg_mse:.2e}\")\n",
    "print(f\"PSNR std: {np.std(psnr_list):.2f} dB\")\n",
    "print(f\"MSE std: {np.std(mse_list):.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f19461",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 100000\n",
    "orig_sample = original_np.flatten()\n",
    "recon_sample = reconstructed_np.flatten()\n",
    "if len(orig_sample) > n_points:\n",
    "    idx = np.random.choice(len(orig_sample), n_points, replace=False)\n",
    "    orig_sample = orig_sample[idx]; recon_sample = recon_sample[idx]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(orig_sample, recon_sample, s=2, alpha=.5)\n",
    "lims = [min(orig_sample.min(), recon_sample.min()),\n",
    "        max(orig_sample.max(), recon_sample.max())]\n",
    "plt.plot(lims, lims, 'k--', linewidth=1)\n",
    "plt.xlabel('Original voxel'); plt.ylabel('Reconstructed voxel')\n",
    "plt.title('Voxel-wise Scatter (diag = perfect)')\n",
    "plt.grid(True, alpha=.3); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20837d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- L2 norm of each embedding vector ---\n",
    "embed_norm = torch.linalg.norm(model.quantizer.embedding.data, dim=1).cpu().numpy()\n",
    "plt.figure(figsize=(10,2))\n",
    "plt.bar(range(NUM_EMBEDDINGS), embed_norm, width=1.0)\n",
    "plt.title('Codebook Embedding L2 Norms'); plt.xlabel('Code Index'); plt.ylabel('Norm')\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f22a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mip(vol, axis):\n",
    "    \"\"\"Maximum-intensity projection along a single axis.\"\"\"\n",
    "    return vol.max(axis=axis)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 7))\n",
    "views = [(0, 'XY MIP'),   # collapse Z\n",
    "         (1, 'XZ MIP'),   # collapse Y\n",
    "         (2, 'YZ MIP')]   # collapse X\n",
    "\n",
    "def vector_to_rgb(vol):         \n",
    "    \"\"\"Convert a 3D vector volume to RGB by mapping each vector component to a color channel.\"\"\"\n",
    "    # Normalize vector components from [-1, 1] to color components [0, 1]\n",
    "    return (vol * 0.5) + 0.5\n",
    "\n",
    "for col, (axis_to_collapse, title) in enumerate(views):\n",
    "    axes[0, col].imshow(mip(vector_to_rgb(original_np), axis=axis_to_collapse), cmap='viridis')\n",
    "    axes[0, col].set_title(f'Original {title}')\n",
    "    axes[0, col].axis('off')\n",
    "\n",
    "    axes[1, col].imshow(mip(vector_to_rgb(reconstructed_np), axis=axis_to_collapse), cmap='viridis')\n",
    "    axes[1, col].set_title(f'Reconstructed {title}')\n",
    "    axes[1, col].axis('off')\n",
    "\n",
    "plt.suptitle('Maximum-Intensity Projections (3-view)', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c617293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 1. Build a per-block latent vector ----------\n",
    "model.eval()\n",
    "latents, errs = [], []          # errs = optional colouring\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in DataLoader(vdb_dataset,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=False):\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        idx = model.encode(batch).long()               # (B, Z, Y, X) indices\n",
    "        emb = model.quantizer.embedding[idx.view(-1)]  # (B*Z*Y*X, C)\n",
    "        emb = emb.view(*idx.shape, -1)                 # (B, Z, Y, X, C)\n",
    "        mean_emb = emb.mean(dim=(1, 2, 3))             # (B, C)\n",
    "        latents.append(mean_emb.cpu())\n",
    "        \n",
    "        # Optional: per-block MSE for coloured scatter\n",
    "        rec = model.decode(idx)\n",
    "        errs.append(((batch - rec) ** 2)\n",
    "                    .view(len(batch), -1)\n",
    "                    .mean(dim=1)\n",
    "                    .cpu())\n",
    "\n",
    "latents = torch.cat(latents, dim=0).numpy()   # (N, C)\n",
    "errs    = torch.cat(errs, dim=0).numpy()      # (N,)\n",
    "\n",
    "# ---------- 2. PCA to 2-D ----------\n",
    "pca2 = PCA(n_components=2, random_state=0)\n",
    "latents_2d = pca2.fit_transform(latents)      # (N, 2)\n",
    "\n",
    "\n",
    "sc = plt.scatter(latents_2d[:, 0],\n",
    "                 latents_2d[:, 1],\n",
    "                 c=errs,                 # <- set to None for uniform colour\n",
    "                 cmap='magma',\n",
    "                 s=4,\n",
    "                 alpha=0.2)\n",
    "if sc.get_array() is not None:           # only if colouring by a value\n",
    "    plt.colorbar(sc, label='Block MSE')\n",
    "\n",
    "plt.title('Latent Space Sampling (PCA-2D, viridis)')\n",
    "plt.xlabel('PC-1'); plt.ylabel('PC-2')\n",
    "plt.grid(True, alpha=.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
